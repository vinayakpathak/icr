{
  "converged_seeds": 5,
  "convergence_rate": 1.0,
  "final_tokens": {
    "max": 280000,
    "mean": 280000.0,
    "median": 280000.0,
    "min": 280000
  },
  "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
  "num_seeds": 5,
  "seed_summaries": [
    {
      "converged": true,
      "convergence_checkpoint": 280000,
      "effective_context_window": 256,
      "final_tokens": 280000,
      "final_unigram": [
        4.642857142857143e-05,
        0.0,
        0.07471428571428572,
        0.03748928571428571,
        0.007710714285714286,
        0.034307142857142855,
        0.007060714285714286,
        0.01817857142857143,
        0.033107142857142856,
        0.024139285714285714,
        0.009328571428571429,
        0.015092857142857142,
        0.030317857142857143,
        0.0197,
        0.0062107142857142856,
        0.0070464285714285715,
        0.03994285714285714,
        0.0025464285714285714,
        0.031078571428571428,
        0.013882142857142857,
        0.025775,
        0.008646428571428572,
        0.128775,
        0.011335714285714286,
        0.019592857142857144,
        0.006817857142857143,
        0.04391071428571429,
        0.012235714285714286,
        0.03738214285714286,
        0.03324642857142857,
        0.006303571428571428,
        0.024935714285714287,
        0.014417857142857144,
        0.06143571428571429,
        0.060067857142857145,
        0.035385714285714284,
        0.004675,
        0.0030535714285714285,
        0.01902857142857143,
        0.0007178571428571428,
        0.003014285714285714,
        0.014939285714285714,
        0.0062,
        0.003971428571428571,
        0.0019357142857142856,
        0.0001,
        9.642857142857143e-05,
        7.5e-05,
        7.142857142857143e-06,
        1.785714285714286e-05,
        3.5714285714285714e-06
      ],
      "max_order": 3,
      "max_position_embeddings": 256,
      "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
      "runtime_sec": 21394.571623563766,
      "seed": 0,
      "start_token_id": 3,
      "start_token_mode": "bos",
      "stop_reason": "converged",
      "supports": {
        "bigram_min_support": 500,
        "trigram_min_support": 200
      },
      "thresholds": {
        "bigram_tv_p95": 0.03,
        "trigram_tv_p95": 0.05,
        "unigram_max_delta": 0.002,
        "window_checkpoints": 5
      },
      "vocab_size": 51
    },
    {
      "converged": true,
      "convergence_checkpoint": 280000,
      "effective_context_window": 256,
      "final_tokens": 280000,
      "final_unigram": [
        0.00024642857142857143,
        0.0,
        0.11257857142857143,
        0.04776428571428572,
        0.013532142857142857,
        0.032467857142857146,
        0.009932142857142856,
        0.01752142857142857,
        0.04087857142857143,
        0.04935,
        0.01247857142857143,
        0.010332142857142857,
        0.02964642857142857,
        0.038714285714285715,
        0.004696428571428571,
        0.008810714285714286,
        0.044939285714285716,
        0.0024035714285714285,
        0.02395,
        0.019921428571428573,
        0.030089285714285714,
        0.008167857142857143,
        0.03876071428571429,
        0.016864285714285714,
        0.005014285714285714,
        0.004064285714285714,
        0.043832142857142854,
        0.01185,
        0.044196428571428574,
        0.040935714285714284,
        0.012417857142857144,
        0.03356428571428571,
        0.013889285714285715,
        0.033185714285714284,
        0.02964642857142857,
        0.016714285714285713,
        0.016264285714285714,
        0.007232142857142857,
        0.02915,
        0.0016178571428571429,
        0.0024964285714285713,
        0.02738214285714286,
        0.004689285714285714,
        0.0030785714285714288,
        0.0033107142857142858,
        0.0004,
        0.0006392857142857143,
        0.0002892857142857143,
        1.0714285714285714e-05,
        7.142857142857143e-05,
        1.0714285714285714e-05
      ],
      "max_order": 3,
      "max_position_embeddings": 256,
      "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
      "runtime_sec": 21404.300640821457,
      "seed": 1,
      "start_token_id": 3,
      "start_token_mode": "bos",
      "stop_reason": "converged",
      "supports": {
        "bigram_min_support": 500,
        "trigram_min_support": 200
      },
      "thresholds": {
        "bigram_tv_p95": 0.03,
        "trigram_tv_p95": 0.05,
        "unigram_max_delta": 0.002,
        "window_checkpoints": 5
      },
      "vocab_size": 51
    },
    {
      "converged": true,
      "convergence_checkpoint": 280000,
      "effective_context_window": 256,
      "final_tokens": 280000,
      "final_unigram": [
        0.0001392857142857143,
        0.0,
        0.08984642857142858,
        0.03611428571428572,
        0.01315357142857143,
        0.04162142857142857,
        0.014217857142857143,
        0.021246428571428572,
        0.052564285714285716,
        0.03227142857142857,
        0.009303571428571428,
        0.009007142857142858,
        0.032985714285714285,
        0.01835,
        0.010703571428571429,
        0.0036928571428571427,
        0.04462857142857143,
        0.003007142857142857,
        0.020967857142857142,
        0.033046428571428574,
        0.025782142857142858,
        0.010807142857142857,
        0.039721428571428574,
        0.014882142857142858,
        0.03938928571428572,
        0.004796428571428571,
        0.02495,
        0.008335714285714287,
        0.10093214285714286,
        0.035885714285714285,
        0.008610714285714286,
        0.025632142857142857,
        0.012685714285714286,
        0.046785714285714285,
        0.022842857142857144,
        0.016389285714285714,
        0.0059357142857142855,
        0.0035714285714285713,
        0.027260714285714287,
        0.0027035714285714284,
        0.004789285714285715,
        0.01612857142857143,
        0.006310714285714286,
        0.0029607142857142857,
        0.002939285714285714,
        0.00035357142857142857,
        0.0010285714285714286,
        0.0006392857142857143,
        1.4285714285714285e-05,
        6.428571428571429e-05,
        3.5714285714285714e-06
      ],
      "max_order": 3,
      "max_position_embeddings": 256,
      "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
      "runtime_sec": 21396.671027183533,
      "seed": 2,
      "start_token_id": 3,
      "start_token_mode": "bos",
      "stop_reason": "converged",
      "supports": {
        "bigram_min_support": 500,
        "trigram_min_support": 200
      },
      "thresholds": {
        "bigram_tv_p95": 0.03,
        "trigram_tv_p95": 0.05,
        "unigram_max_delta": 0.002,
        "window_checkpoints": 5
      },
      "vocab_size": 51
    },
    {
      "converged": true,
      "convergence_checkpoint": 280000,
      "effective_context_window": 256,
      "final_tokens": 280000,
      "final_unigram": [
        0.00015357142857142856,
        0.0,
        0.07560357142857142,
        0.04878214285714286,
        0.010064285714285715,
        0.03533928571428571,
        0.014960714285714286,
        0.022510714285714287,
        0.05338214285714286,
        0.028753571428571427,
        0.014660714285714286,
        0.023578571428571428,
        0.04206785714285714,
        0.025464285714285714,
        0.011367857142857143,
        0.005646428571428571,
        0.048592857142857146,
        0.0026785714285714286,
        0.022382142857142857,
        0.028289285714285715,
        0.03352857142857143,
        0.010071428571428571,
        0.03394642857142857,
        0.02363214285714286,
        0.027546428571428572,
        0.007160714285714286,
        0.024067857142857144,
        0.009217857142857142,
        0.066225,
        0.03579642857142857,
        0.009532142857142857,
        0.025785714285714287,
        0.019678571428571427,
        0.025942857142857143,
        0.027342857142857144,
        0.02909642857142857,
        0.00525,
        0.003928571428571429,
        0.01747857142857143,
        0.0008285714285714286,
        0.002675,
        0.03356428571428571,
        0.005414285714285714,
        0.0032964285714285712,
        0.0029821428571428573,
        0.00022142857142857142,
        0.0006357142857142857,
        0.0008107142857142857,
        3.5714285714285714e-06,
        5.357142857142857e-05,
        7.142857142857143e-06
      ],
      "max_order": 3,
      "max_position_embeddings": 256,
      "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
      "runtime_sec": 21386.39822936058,
      "seed": 3,
      "start_token_id": 3,
      "start_token_mode": "bos",
      "stop_reason": "converged",
      "supports": {
        "bigram_min_support": 500,
        "trigram_min_support": 200
      },
      "thresholds": {
        "bigram_tv_p95": 0.03,
        "trigram_tv_p95": 0.05,
        "unigram_max_delta": 0.002,
        "window_checkpoints": 5
      },
      "vocab_size": 51
    },
    {
      "converged": true,
      "convergence_checkpoint": 280000,
      "effective_context_window": 256,
      "final_tokens": 280000,
      "final_unigram": [
        0.00014642857142857144,
        0.0,
        0.04367857142857143,
        0.015085714285714286,
        0.008921428571428571,
        0.03887142857142857,
        0.014075,
        0.021435714285714287,
        0.042182142857142856,
        0.0231,
        0.014882142857142858,
        0.015428571428571429,
        0.03239285714285714,
        0.018217857142857143,
        0.006207142857142857,
        0.012146428571428572,
        0.06957142857142858,
        0.0029464285714285716,
        0.030335714285714285,
        0.0486,
        0.032592857142857146,
        0.014139285714285714,
        0.074,
        0.01637857142857143,
        0.013460714285714286,
        0.005614285714285714,
        0.02653214285714286,
        0.0216,
        0.07815714285714286,
        0.03246071428571429,
        0.015907142857142856,
        0.026939285714285714,
        0.013382142857142856,
        0.037032142857142854,
        0.03131428571428571,
        0.022442857142857143,
        0.004357142857142857,
        0.0047,
        0.026564285714285714,
        0.0021035714285714286,
        0.007667857142857143,
        0.023392857142857142,
        0.004907142857142857,
        0.0036357142857142855,
        0.0018392857142857143,
        0.00014285714285714287,
        0.00020357142857142858,
        0.0002642857142857143,
        3.5714285714285714e-06,
        3.2142857142857144e-05,
        7.142857142857143e-06
      ],
      "max_order": 3,
      "max_position_embeddings": 256,
      "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
      "runtime_sec": 21403.546371936798,
      "seed": 4,
      "start_token_id": 3,
      "start_token_mode": "bos",
      "stop_reason": "converged",
      "supports": {
        "bigram_min_support": 500,
        "trigram_min_support": 200
      },
      "thresholds": {
        "bigram_tv_p95": 0.03,
        "trigram_tv_p95": 0.05,
        "unigram_max_delta": 0.002,
        "window_checkpoints": 5
      },
      "vocab_size": 51
    }
  ],
  "seeds": [
    0,
    1,
    2,
    3,
    4
  ],
  "vocab_size": 51
}