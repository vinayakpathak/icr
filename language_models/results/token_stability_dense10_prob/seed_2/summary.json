{
  "converged": true,
  "convergence_checkpoint": 280000,
  "effective_context_window": 256,
  "final_tokens": 280000,
  "final_unigram": [
    0.0001392857142857143,
    0.0,
    0.08984642857142858,
    0.03611428571428572,
    0.01315357142857143,
    0.04162142857142857,
    0.014217857142857143,
    0.021246428571428572,
    0.052564285714285716,
    0.03227142857142857,
    0.009303571428571428,
    0.009007142857142858,
    0.032985714285714285,
    0.01835,
    0.010703571428571429,
    0.0036928571428571427,
    0.04462857142857143,
    0.003007142857142857,
    0.020967857142857142,
    0.033046428571428574,
    0.025782142857142858,
    0.010807142857142857,
    0.039721428571428574,
    0.014882142857142858,
    0.03938928571428572,
    0.004796428571428571,
    0.02495,
    0.008335714285714287,
    0.10093214285714286,
    0.035885714285714285,
    0.008610714285714286,
    0.025632142857142857,
    0.012685714285714286,
    0.046785714285714285,
    0.022842857142857144,
    0.016389285714285714,
    0.0059357142857142855,
    0.0035714285714285713,
    0.027260714285714287,
    0.0027035714285714284,
    0.004789285714285715,
    0.01612857142857143,
    0.006310714285714286,
    0.0029607142857142857,
    0.002939285714285714,
    0.00035357142857142857,
    0.0010285714285714286,
    0.0006392857142857143,
    1.4285714285714285e-05,
    6.428571428571429e-05,
    3.5714285714285714e-06
  ],
  "max_order": 3,
  "max_position_embeddings": 256,
  "model_id": "phonemetransformers/GPT2-85M-CHAR-PHON",
  "runtime_sec": 21396.671027183533,
  "seed": 2,
  "start_token_id": 3,
  "start_token_mode": "bos",
  "stop_reason": "converged",
  "supports": {
    "bigram_min_support": 500,
    "trigram_min_support": 200
  },
  "thresholds": {
    "bigram_tv_p95": 0.03,
    "trigram_tv_p95": 0.05,
    "unigram_max_delta": 0.002,
    "window_checkpoints": 5
  },
  "vocab_size": 51
}